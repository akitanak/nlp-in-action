{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "027a07e4-3944-43f6-9e79-1fc5393e8345",
   "metadata": {},
   "source": [
    "# Natural Language Processing in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a134f2c-355d-4173-823a-62700ba9e9b9",
   "metadata": {},
   "source": [
    "## 2. Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f71a2da-1e56-414b-967e-80921d914721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentence\n",
    "sentence = \"Thomas Jefferson began building Monticello at the age of 26.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8de4ca0d-ac3e-4f6a-875a-3da4517819ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " 'Jefferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'Monticello',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " '26.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a7be43d-a381-4bcc-bbe4-c6ba2257827f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " 'Jefferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'Monticello',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " '26.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str.split(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0f171-069d-4f0f-8f9c-ed9475537a56",
   "metadata": {},
   "source": [
    "### One-hot vector を作ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eec1e230-cf2c-4e47-818e-9c1d3a961973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8527d50-965b-45ff-ae08-40a08c28369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following packages are already present in the pyproject.toml and will be skipped:\n",
      "\n",
      "  • \u001b[36mpandas\u001b[0m\n",
      "\n",
      "If you want to update it to the latest compatible version, you can use `poetry update package`.\n",
      "If you prefer to upgrade it to the latest available version, you can use `poetry add package@latest`.\n",
      "\n",
      "Nothing to add.\n"
     ]
    }
   ],
   "source": [
    "!poetry add pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbfdd6a4-d65b-470d-bca4-7d463f0b12f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75cd17cf-c019-4613-a44e-0f3ac6cc3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sequence = str.split(sentence)\n",
    "vocab = sorted(set(token_sequence))\n",
    "num_tokens = len(token_sequence)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b09f10f2-42a1-41b1-8940-6af9acd1e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_vectors = np.zeros((num_tokens, vocab_size), int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c88404fd-91ce-49be-8000-661771005d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, word in enumerate(token_sequence):\n",
    "    onehot_vectors[i, vocab.index(word)] = 1\n",
    "\n",
    "onehot_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ff0b523-b65b-4f92-a3d0-272a736b11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(onehot_vectors, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4744bb26-09dc-43a3-8f7c-0c4e176b43e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>26.</th>\n",
       "      <th>Jefferson</th>\n",
       "      <th>Monticello</th>\n",
       "      <th>Thomas</th>\n",
       "      <th>age</th>\n",
       "      <th>at</th>\n",
       "      <th>began</th>\n",
       "      <th>building</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   26.  Jefferson  Monticello  Thomas  age  at  began  building  of  the\n",
       "0    0          0           0       1    0   0      0         0   0    0\n",
       "1    0          1           0       0    0   0      0         0   0    0\n",
       "2    0          0           0       0    0   0      1         0   0    0\n",
       "3    0          0           0       0    0   0      0         1   0    0\n",
       "4    0          0           1       0    0   0      0         0   0    0\n",
       "5    0          0           0       0    0   1      0         0   0    0\n",
       "6    0          0           0       0    0   0      0         0   0    1\n",
       "7    0          0           0       0    1   0      0         0   0    0\n",
       "8    0          0           0       0    0   0      0         0   1    0\n",
       "9    1          0           0       0    0   0      0         0   0    0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d7dd3-5bd3-4a0b-93c1-f229416e1d07",
   "metadata": {},
   "source": [
    "### Bag of Words を作ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63ec47be-2b75-4fb1-a8d4-6543e11dd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = (\n",
    "\"Thomas Jefferson began building Monticello at the age of 26.\\n\"\n",
    "\"Construction was done mostly by local masons and carpenters.\\n\"\n",
    "\"He moved into the South Pavilion in 1770.\\n\"\n",
    "\"Turning Monticello into a neoclassical masterpiece was Jefferson's obsession.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80c5b339-44e6-4001-95aa-13c6850d39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ef3f6fb-79df-4f2d-af39-8b6c9e5fddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sent in enumerate(sentences.split('\\n')):\n",
    "    corpus[f\"sent{i}\"] = dict((tok, 1) for tok in sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9cc0cb68-940a-4023-8a48-65f6998d0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2199ce38-a493-4529-930a-eddaf8a195ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thomas</th>\n",
       "      <th>Jefferson</th>\n",
       "      <th>began</th>\n",
       "      <th>building</th>\n",
       "      <th>Monticello</th>\n",
       "      <th>at</th>\n",
       "      <th>the</th>\n",
       "      <th>age</th>\n",
       "      <th>of</th>\n",
       "      <th>26.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Thomas  Jefferson  began  building  Monticello  at  the  age  of  26.\n",
       "sent0       1          1      1         1           1   1    1    1   1    1\n",
       "sent1       0          0      0         0           0   0    0    0   0    0\n",
       "sent2       0          0      0         0           0   0    1    0   0    0\n",
       "sent3       0          0      0         0           1   0    0    0   0    0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "603d57d0-cb9a-4ceb-839a-a954d1599f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thomas</th>\n",
       "      <th>Jefferson</th>\n",
       "      <th>began</th>\n",
       "      <th>building</th>\n",
       "      <th>Monticello</th>\n",
       "      <th>at</th>\n",
       "      <th>the</th>\n",
       "      <th>age</th>\n",
       "      <th>of</th>\n",
       "      <th>26.</th>\n",
       "      <th>...</th>\n",
       "      <th>South</th>\n",
       "      <th>Pavilion</th>\n",
       "      <th>in</th>\n",
       "      <th>1770.</th>\n",
       "      <th>Turning</th>\n",
       "      <th>a</th>\n",
       "      <th>neoclassical</th>\n",
       "      <th>masterpiece</th>\n",
       "      <th>Jefferson's</th>\n",
       "      <th>obsession.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Thomas  Jefferson  began  building  Monticello  at  the  age  of  26.  \\\n",
       "sent0       1          1      1         1           1   1    1    1   1    1   \n",
       "sent1       0          0      0         0           0   0    0    0   0    0   \n",
       "sent2       0          0      0         0           0   0    1    0   0    0   \n",
       "sent3       0          0      0         0           1   0    0    0   0    0   \n",
       "\n",
       "       ...  South  Pavilion  in  1770.  Turning  a  neoclassical  masterpiece  \\\n",
       "sent0  ...      0         0   0      0        0  0             0            0   \n",
       "sent1  ...      0         0   0      0        0  0             0            0   \n",
       "sent2  ...      1         1   1      1        0  0             0            0   \n",
       "sent3  ...      0         0   0      0        1  1             1            1   \n",
       "\n",
       "       Jefferson's  obsession.  \n",
       "sent0            0           0  \n",
       "sent1            0           0  \n",
       "sent2            0           0  \n",
       "sent3            1           1  \n",
       "\n",
       "[4 rows x 32 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13b719f1-649e-4222-ae7c-92abfa8813de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a6282f8-56a8-4b07-b735-cb225875eb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "330d4e63-2d1e-4798-b07c-5724d480c54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5e5f8cd-9590-45cb-8c3b-fa47ec164db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8038831c-2739-4109-a193-c30946aef39f",
   "metadata": {},
   "source": [
    "### 正規表現でトークナイズを改善する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "004dc520-34b6-43e5-969d-3a98d987d08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " 'Jefferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'Monticello',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " '26']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r\"[-\\s.,;!?]+\")\n",
    "tokens = pattern.split(sentence)\n",
    "tokens = [x for x in tokens if x and x not in \"- \\t\\n.,;!?\"]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be0715-505e-40b5-bdf4-b25e8bec4490",
   "metadata": {},
   "source": [
    "### ライブラリを使ってトークナイズする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa74a7b-4655-4156-b139-83936cfcfc30",
   "metadata": {},
   "source": [
    "各ライブラリの特徴は次の通り。\n",
    "- spaCy: Accurate , flexible, fast, Python\n",
    "- Stanford CoreNLP: More accurate, less flexible, fast, depends on Java 8\n",
    "- NLTK: Standard used by many NLP contests and comparisons, popular, Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c597304-9057-47e8-a4c4-da90c08503cc",
   "metadata": {},
   "source": [
    "#### spaCyを使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b37c7f5e-aa0f-48ed-ba6a-229a7cab7f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Thomas, Jefferson, began, building, Monticello, at, the, age, of, 26, .]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# 英語用のトークナイザ等を読み込む\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(sentence)\n",
    "[token for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6282d042-3464-44af-8f5d-7e0feb44ffe1",
   "metadata": {},
   "source": [
    "#### NLTKを使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1609ca1-9e50-45c8-b016-8d3eca26f757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " 'Jefferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'Monticello',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " '26',\n",
       " '.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r\"\\w+|$[0-9.]+|\\S+\")\n",
    "tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f2a0b1-6fb3-4e6c-8c63-bb455b752696",
   "metadata": {},
   "source": [
    "## NLTK の Treebank Tokenizer を使ってみる\n",
    "wasn't のような短縮形を was n't のように分割してくれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b50a641c-3592-43e8-b36b-9c5140212b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monticello',\n",
       " 'was',\n",
       " \"n't\",\n",
       " 'designed',\n",
       " 'as',\n",
       " 'UNESCO',\n",
       " 'World',\n",
       " 'Heritage',\n",
       " 'Site',\n",
       " 'untill',\n",
       " '1987',\n",
       " '.']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "sentence2 = \"\"\"Monticello wasn't designed as UNESCO World Heritage Site untill 1987.\"\"\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(sentence2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb5779b-46ca-4f4e-9b01-f789cfb64187",
   "metadata": {},
   "source": [
    "## n-gramで語彙を広げる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e513503-f605-4818-870a-2a511f616bad",
   "metadata": {},
   "source": [
    "\"ice cream\" などのように複数単語で成り立っている言葉は、単語でトークナイズしてしまうとそのままでは文書中の意図した意味にならない。こういった言葉をn-gramを使って扱えるようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f42acc6-a175-4b37-a8e7-1f833a18790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "347d34b6-f8fc-408d-8612-c83d9674de2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thomas', 'Jefferson'),\n",
       " ('Jefferson', 'began'),\n",
       " ('began', 'building'),\n",
       " ('building', 'Monticello'),\n",
       " ('Monticello', 'at'),\n",
       " ('at', 'the'),\n",
       " ('the', 'age'),\n",
       " ('age', 'of'),\n",
       " ('of', '26')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(tokens, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "80e84c03-8146-45a3-8838-cfd2339e5ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thomas', 'Jefferson', 'began'),\n",
       " ('Jefferson', 'began', 'building'),\n",
       " ('began', 'building', 'Monticello'),\n",
       " ('building', 'Monticello', 'at'),\n",
       " ('Monticello', 'at', 'the'),\n",
       " ('at', 'the', 'age'),\n",
       " ('the', 'age', 'of'),\n",
       " ('age', 'of', '26')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(tokens, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d6de0-b7ad-4b41-8da6-0c5ff9d8bcb1",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca800853-efee-4863-a7f7-4b53257161be",
   "metadata": {},
   "source": [
    "文章の本質的な意味に寄与せず、かつ多くの文書で出てくる言葉をStop Wordsという。\n",
    "例えば、以下のようなものがある。\n",
    "- a, an\n",
    "- the, this\n",
    "- and, or\n",
    "- of, on\n",
    "歴史的に計算負荷をへらすことを目的などにしてStop wordsは除去されることが多いが、わずかながらにも文書の意味に寄与することがある。例えば、以下のような文では、Stop wordsの有無で文意が変わってしまう。\n",
    "- Mark reported to the CEO.\n",
    "- Suzanne reported as the CEO to the board.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2cef67ca-ec02-4f5a-a9b4-432ffe94e44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akitanak/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTKのStop Wordsには次のようなものが含まれている。\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a656a1af-ef4c-46fe-8430-c42047be82f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc38d1c-fa4f-44f3-b393-da4f5682cd91",
   "metadata": {},
   "source": [
    "## 語彙を正規化する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfd221-de5e-4c56-88c2-4e02e154c5fc",
   "metadata": {},
   "source": [
    "文章中には、単語の活用等によって異なるスペリングでも同じ意味を持つことがある。このようなものを一つの単語に統一するためのテクニックとして、以下のようなものがある。\n",
    "- Case Folding\n",
    "- Stemming\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842cc9af-ab37-4274-9202-b602bec42eb3",
   "metadata": {},
   "source": [
    "### Case Folding\n",
    "Capitalizatinを修正して単語のスペルを揃える。すべてをlower caseにしてしまうと、upper caseであることに意味があるものが失われてしまうので注意。文頭の単語のみ小文字にする等の工夫が必要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b1225f4-d414-4c1d-9d2f-6092add97c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas', 'Jefferson', 'began', 'building', 'Monticello', 'at', 'the', 'age', 'of', '26']\n",
      "['thomas', 'jefferson', 'began', 'building', 'monticello', 'at', 'the', 'age', 'of', '26']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)\n",
    "normalized_tokens = [x.lower() for x in tokens]\n",
    "print(normalized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5aeab7-f05c-4ea3-88e9-4b2b53d29b51",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81255909-454f-48f6-bc49-6f5c73ee3e5b",
   "metadata": {},
   "source": [
    "複数形や所有格等の活用形における共通的な単語の stem を特定する手法である。たとえば、 \"house\" と \"houses\"、\"house's\" を \"house\" に揃える。スペリングを元に機械的に stem に変換するため、文中の意味を失うこともある。\n",
    "検索エンジンなどで利用すると、対象となる文書が増えるためrecallは改善するが、その分余計な文書も含まれるようになりprecisionに悪影響を与えることになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25215be0-db7a-4e6b-ac17-0350a11bc998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house\n",
      "doctor house call\n"
     ]
    }
   ],
   "source": [
    "def stem(words):\n",
    "    return \" \".join([re.findall('^(.*ss|.*?)(s)?$', word)[0][0].strip(\"'\") for word in words.lower().split()])\n",
    "\n",
    "print(stem(\"houses\"))\n",
    "print(stem(\"Doctor House's calls\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561459b-1f00-4234-86d6-7a83512932e1",
   "metadata": {},
   "source": [
    "ポピュラーなstemmingアルゴリズムとして、Porter stemmer と Snowball stemmer がある。どちらもMartine Porterによって考案されたアルゴリズムで Snowball stemmer は Porter stemmer の拡張版である。\n",
    "[ここ](https://github.com/jedijulia/porter-stemmer/blob/ master/stemmer.py)にPorter stemmerのpython実装がある。\n",
    "nltk が Porter stemmer の実装を提供している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "032a48ca-8803-45ef-9416-9a1c5ade4ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dish washer wash dish'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\" \".join([stemmer.stem(w).strip(\"'\") for w in \"dish washer's washed dished\".split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28342087-f2bf-4859-aa58-c0786ef0f4bc",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a7092-00dc-45fa-b0ba-fbd38b561ae5",
   "metadata": {},
   "source": [
    "意味的に同じ幹に正規化する手法である。Lemmatizer は Part of Speech(POS)(品詞)も単語と一緒に受け取り処理を行う。Lemmatization は Stemming よりも精度が高くなることが期待できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "061fa974-1968-47ed-876b-b2c516980858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better\n",
      "good\n",
      "good\n",
      "goods\n",
      "good\n",
      "goodness\n",
      "goodness\n",
      "best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/akitanak/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"better\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"good\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"goods\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"goods\", pos=\"n\"))\n",
    "print(lemmatizer.lemmatize(\"goodness\", pos=\"n\"))\n",
    "print(lemmatizer.lemmatize(\"goodness\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcbbd84-f3ca-4fd4-a401-7bcb557e21a3",
   "metadata": {},
   "source": [
    "## 感情分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa4b1da-2788-4d9c-a4ce-bfaf03532775",
   "metadata": {},
   "source": [
    "感情分析の方法には２つのアプローチがある。\n",
    "- 人によって構成されたルールベースのアルゴリズム\n",
    "  - キーワードごとに感情スコアを人間が設定し、文書中に登場するキーワードを元にスコアリングする。\n",
    "- 予めラベル付けされたデータによる機械学習モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06926266-9c8f-4044-bf26-e0999c8a0eca",
   "metadata": {},
   "source": [
    "### VADER - ルールベースのアルゴリズム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2940ef83-4b1f-4480-9a0e-8d4fe4653790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version \u001b[1m^3.3.2\u001b[0m for \u001b[36mvaderSentiment\u001b[0m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[0m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[0m \u001b[39;2m(1.1s)\u001b[0m\n",
      "\n",
      "\u001b[34mWriting lock file\u001b[0m\n",
      "\n",
      "\u001b[1mPackage operations\u001b[0m: \u001b[34m1\u001b[0m install, \u001b[34m0\u001b[0m updates, \u001b[34m0\u001b[0m removals\n",
      "\n",
      "  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mvadersentiment\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m3.3.2\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mPending...\u001b[0m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mvadersentiment\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m3.3.2\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mDownloading...\u001b[0m \u001b[1m0%\u001b[0m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mvadersentiment\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m3.3.2\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mDownloading...\u001b[0m \u001b[1m100%\u001b[0m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mvadersentiment\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m3.3.2\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mDownloading...\u001b[0m \u001b[1m100%\u001b[0m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mvadersentiment\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m3.3.2\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mInstalling...\u001b[0m\n",
      "\u001b[1A\u001b[0J  \u001b[32;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mvadersentiment\u001b[0m\u001b[39m (\u001b[0m\u001b[32m3.3.2\u001b[0m\u001b[39m)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!poetry add vadersentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "96806ab8-43c5-4fc3-8279-76c4fa2b7f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"( '}{' )\", 1.6),\n",
       " (\"can't stand\", -2.0),\n",
       " ('fed up', -1.8),\n",
       " ('screwed up', -1.5)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "[(tok, score) for tok, score in sa.lexicon.items() if \" \" in tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e64b4997-3c6f-4c0f-8afb-37d41e4f8a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.661, 'pos': 0.339, 'compound': 0.6249}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.polarity_scores(text=\"Python is very readable and it's great for NLP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a8f47a70-cc56-43fa-b5d2-b85fe05a1610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.737, 'pos': 0.263, 'compound': 0.431}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.polarity_scores(text=\"Python is not a bad choice for most application.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b1243492-9dc0-4eba-9683-1a607ef7783f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9428: Absolutely perfect! Love it! :-) :-) :-)\n",
      "-0.8768: Horrible! Completely useless. :(\n",
      "-0.1531: It was OK. Some good and some bad things.\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"Absolutely perfect! Love it! :-) :-) :-)\",\n",
    "    \"Horrible! Completely useless. :(\",\n",
    "    \"It was OK. Some good and some bad things.\"\n",
    "]\n",
    "\n",
    "for doc in corpus:\n",
    "    scores = sa.polarity_scores(doc)\n",
    "    print(f\"{scores['compound']}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4ff536-887a-4a50-aec6-03680f88d185",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab5cb5-5937-4a3c-8e8a-e50beb3ede14",
   "metadata": {},
   "source": [
    "Naive Bayesモデルは対象のドキュメントの集合から目的変数となるキーワードを見つける。\n",
    "下記サンプルのデータは[ここ](https://github.com/totalgood/nlpia/raw/master/src/nlpia/data/hutto_ICWSM_2014/movieReviewSnippets_GroundTruth.csv.gz)からダウンロードした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bde2259e-fec3-4f7b-bee2-83109add4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path(\"../data/movieReviewSnippets_GroundTruth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "154ebcb0-1e7d-4349-8493-c0c4d86cce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5a9fb416-e382-4f0b-b1f4-eb3a55466f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ee5ea1c8-66f0-47cc-b64d-ae1f7c80c4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.27</td>\n",
       "      <td>The Rock is destined to be the 21st Century's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.53</td>\n",
       "      <td>The gorgeously elaborate continuation of ''The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>Effective but too tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.47</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.73</td>\n",
       "      <td>Emerges as something rare, an issue movie that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  sentiment                                               text\n",
       "0   1       2.27  The Rock is destined to be the 21st Century's ...\n",
       "1   2       3.53  The gorgeously elaborate continuation of ''The...\n",
       "2   3      -0.60                     Effective but too tepid biopic\n",
       "3   4       1.47  If you sometimes like to go to the movies to h...\n",
       "4   5       1.73  Emerges as something rare, an issue movie that..."
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "faf567fe-1625-4cdf-b486-e2cb4747896b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10605.00</td>\n",
       "      <td>10605.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5303.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3061.54</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2652.00</td>\n",
       "      <td>-1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5303.00</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7954.00</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10605.00</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  sentiment\n",
       "count  10605.00   10605.00\n",
       "mean    5303.00       0.00\n",
       "std     3061.54       1.92\n",
       "min        1.00      -3.88\n",
       "25%     2652.00      -1.77\n",
       "50%     5303.00      -0.08\n",
       "75%     7954.00       1.83\n",
       "max    10605.00       3.94"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bb31160d-66b7-4156-8180-549db358b57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10605, 20756)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import casual_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.width', 75)\n",
    "bags_of_words = [Counter(casual_tokenize(text)) for text in movies.text]\n",
    "df_bows = pd.DataFrame.from_records(bags_of_words)\n",
    "df_bows = df_bows.fillna(0).astype(int)\n",
    "df_bows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3882122b-fa66-46c5-8787-ea01892606e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>Rock</th>\n",
       "      <th>is</th>\n",
       "      <th>destined</th>\n",
       "      <th>to</th>\n",
       "      <th>be</th>\n",
       "      <th>the</th>\n",
       "      <th>21st</th>\n",
       "      <th>Century's</th>\n",
       "      <th>new</th>\n",
       "      <th>...</th>\n",
       "      <th>Ill</th>\n",
       "      <th>slummer</th>\n",
       "      <th>Rashomon</th>\n",
       "      <th>dipsticks</th>\n",
       "      <th>Bearable</th>\n",
       "      <th>Staggeringly</th>\n",
       "      <th>’</th>\n",
       "      <th>ve</th>\n",
       "      <th>muttering</th>\n",
       "      <th>dissing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20756 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   The  Rock  is  destined  to  be  the  21st  Century's  new  ...  Ill  \\\n",
       "0    1     1   1         1   2   1    1     1          1    1  ...    0   \n",
       "1    2     0   1         0   0   0    1     0          0    0  ...    0   \n",
       "2    0     0   0         0   0   0    0     0          0    0  ...    0   \n",
       "3    0     0   1         0   4   0    1     0          0    0  ...    0   \n",
       "4    0     0   0         0   0   0    0     0          0    0  ...    0   \n",
       "\n",
       "   slummer  Rashomon  dipsticks  Bearable  Staggeringly  ’  ve  \\\n",
       "0        0         0          0         0             0  0   0   \n",
       "1        0         0          0         0             0  0   0   \n",
       "2        0         0          0         0             0  0   0   \n",
       "3        0         0          0         0             0  0   0   \n",
       "4        0         0          0         0             0  0   0   \n",
       "\n",
       "   muttering  dissing  \n",
       "0          0        0  \n",
       "1          0        0  \n",
       "2          0        0  \n",
       "3          0        0  \n",
       "4          0        0  \n",
       "\n",
       "[5 rows x 20756 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1147367e-f2f0-4a81-94b7-87e4ea6ba873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# case folding で normalization\n",
    "bags_of_words_w_cf = [Counter(casual_tokenize(text.lower())) for text in movies.text]\n",
    "df_bows_cf = pd.DataFrame.from_records(bags_of_words_w_cf)\n",
    "df_bows_cf = df_bows_cf.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e42efcd6-706d-4974-af50-7811767e1305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10605, 18541)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bows_cf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ae56ab36-d2d5-41d9-a231-ba8f45c3b0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>rock</th>\n",
       "      <th>is</th>\n",
       "      <th>destined</th>\n",
       "      <th>to</th>\n",
       "      <th>be</th>\n",
       "      <th>21st</th>\n",
       "      <th>century's</th>\n",
       "      <th>new</th>\n",
       "      <th>'</th>\n",
       "      <th>...</th>\n",
       "      <th>drudgery</th>\n",
       "      <th>snubbing</th>\n",
       "      <th>degenerates</th>\n",
       "      <th>hogwash</th>\n",
       "      <th>slummer</th>\n",
       "      <th>rashomon</th>\n",
       "      <th>dipsticks</th>\n",
       "      <th>’</th>\n",
       "      <th>ve</th>\n",
       "      <th>muttering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18541 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   the  rock  is  destined  to  be  21st  century's  new  '  ...  \\\n",
       "0    2     1   1         1   2   1     1          1    1  4  ...   \n",
       "1    3     0   1         0   0   0     0          0    0  4  ...   \n",
       "2    0     0   0         0   0   0     0          0    0  0  ...   \n",
       "3    1     0   1         0   4   0     0          0    0  0  ...   \n",
       "4    0     0   0         0   0   0     0          0    0  0  ...   \n",
       "\n",
       "   drudgery  snubbing  degenerates  hogwash  slummer  rashomon  \\\n",
       "0         0         0            0        0        0         0   \n",
       "1         0         0            0        0        0         0   \n",
       "2         0         0            0        0        0         0   \n",
       "3         0         0            0        0        0         0   \n",
       "4         0         0            0        0        0         0   \n",
       "\n",
       "   dipsticks  ’  ve  muttering  \n",
       "0          0  0   0          0  \n",
       "1          0  0   0          0  \n",
       "2          0  0   0          0  \n",
       "3          0  0   0          0  \n",
       "4          0  0   0          0  \n",
       "\n",
       "[5 rows x 18541 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bows_cf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a1bb7861-19c9-427b-91db-86d66f0f9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming で normalization\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stemming(word):\n",
    "    return stemmer.stem(word).strip(\"'\")\n",
    "\n",
    "bags_of_words_w_stemmer = [Counter([stemming(word) for word in casual_tokenize(text)]) for text in movies.text]\n",
    "df_bows_stemmer = pd.DataFrame.from_records(bags_of_words_w_stemmer)\n",
    "df_bows_stemmer = df_bows_stemmer.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4107a34b-e408-4ae6-9e90-51fcbfd7f402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10605, 12527)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bows_stemmer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a41e3440-cac8-45b0-8f99-835a005257b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>rock</th>\n",
       "      <th>is</th>\n",
       "      <th>destin</th>\n",
       "      <th>to</th>\n",
       "      <th>be</th>\n",
       "      <th>21st</th>\n",
       "      <th>century</th>\n",
       "      <th>new</th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th>ame</th>\n",
       "      <th>drudgeri</th>\n",
       "      <th>snub</th>\n",
       "      <th>hogwash</th>\n",
       "      <th>slummer</th>\n",
       "      <th>rashomon</th>\n",
       "      <th>dipstick</th>\n",
       "      <th>’</th>\n",
       "      <th>ve</th>\n",
       "      <th>mutter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   the  rock  is  destin  to  be  21st  century  new     ...  ame  \\\n",
       "0    2     1   1       1   2   1     1        1    1  4  ...    0   \n",
       "1    3     0   1       0   0   0     0        0    0  4  ...    0   \n",
       "2    0     0   0       0   0   0     0        0    0  0  ...    0   \n",
       "3    1     0   1       0   4   0     0        0    0  0  ...    0   \n",
       "4    0     0   0       0   0   0     0        0    0  0  ...    0   \n",
       "\n",
       "   drudgeri  snub  hogwash  slummer  rashomon  dipstick  ’  ve  mutter  \n",
       "0         0     0        0        0         0         0  0   0       0  \n",
       "1         0     0        0        0         0         0  0   0       0  \n",
       "2         0     0        0        0         0         0  0   0       0  \n",
       "3         0     0        0        0         0         0  0   0       0  \n",
       "4         0     0        0        0         0         0  0   0       0  \n",
       "\n",
       "[5 rows x 12527 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bows_stemmer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e6a7bd14-1b50-4c2f-80d0-a336587d4a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akitanak/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# stop words を使って次元を削減する\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5c21cf29-341e-409d-b9d2-7fdb57be9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "bags_of_words_stopwords = [Counter([stemming(word) for word in casual_tokenize(text) if word not in stop_words]) for text in movies.text]\n",
    "df_bows_stopwords = pd.DataFrame.from_records(bags_of_words_stopwords)\n",
    "df_bows_stopwords = df_bows_stopwords.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8924f330-4953-4505-b5d0-fc0c142e5b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10605, 12505)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bows_stopwords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "35802b5c-2cd2-44d8-88ae-3b357982b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version \u001b[1m^0.24.2\u001b[0m for \u001b[36mscikit-learn\u001b[0m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[0m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[0m \u001b[39;2m(0.6s)\u001b[0m\n",
      "\n",
      "\u001b[34mWriting lock file\u001b[0m\n",
      "\n",
      "\u001b[1mPackage operations\u001b[0m: \u001b[34m3\u001b[0m installs, \u001b[34m0\u001b[0m updates, \u001b[34m0\u001b[0m removals\n",
      "\n",
      "  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mscipy\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m1.6.1\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mPending...\u001b[0m\n",
      "  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mthreadpoolctl\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m2.1.0\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mPending...\u001b[0m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mthreadpoolctl\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m2.1.0\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mInstalling...\u001b[0m\n",
      "\u001b[2A\u001b[0J  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mthreadpoolctl\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m2.1.0\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mInstalling...\u001b[0m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mscipy\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m1.6.1\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mInstalling...\u001b[0m\n",
      "  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mthreadpoolctl\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m2.1.0\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mInstalling...\u001b[0m\n",
      "\u001b[1A\u001b[0J  \u001b[32;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mthreadpoolctl\u001b[0m\u001b[39m (\u001b[0m\u001b[32m2.1.0\u001b[0m\u001b[39m)\u001b[0m\n",
      "\u001b[2A\u001b[0J  \u001b[32;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mthreadpoolctl\u001b[0m\u001b[39m (\u001b[0m\u001b[32m2.1.0\u001b[0m\u001b[39m)\u001b[0m\n",
      "\u001b[1A\u001b[0J  \u001b[32;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mscipy\u001b[0m\u001b[39m (\u001b[0m\u001b[32m1.6.1\u001b[0m\u001b[39m)\u001b[0m\n",
      "  \u001b[32;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mthreadpoolctl\u001b[0m\u001b[39m (\u001b[0m\u001b[32m2.1.0\u001b[0m\u001b[39m)\u001b[0m\n",
      "  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mscikit-learn\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m0.24.2\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mPending...\u001b[0m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mscikit-learn\u001b[0m\u001b[39m (\u001b[0m\u001b[39;1m0.24.2\u001b[0m\u001b[39m)\u001b[0m: \u001b[34mInstalling...\u001b[0m\n",
      "\u001b[1A\u001b[0J  \u001b[32;1m•\u001b[0m \u001b[39mInstalling \u001b[0m\u001b[36mscikit-learn\u001b[0m\u001b[39m (\u001b[0m\u001b[32m0.24.2\u001b[0m\u001b[39m)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes を使って、sentimentを推論してみる\n",
    "!poetry add scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6ed65278-8a2b-417f-b570-a828180ae711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(df_bows, movies.sentiment > 0)\n",
    "movies[\"predicted_sentiment\"] = (nb.predict_proba(df_bows) * 8 - 4)[:, 1]\n",
    "movies[\"error\"] = (movies.predicted_sentiment - movies.sentiment).abs()\n",
    "movies.error.mean().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "433a92d0-b1c9-4a92-b73b-0cc41f5e65d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>sentiment_ispositive</th>\n",
       "      <th>predicted_ispositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.266667</td>\n",
       "      <td>2.511515</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.533333</td>\n",
       "      <td>3.999904</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-3.655976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.466667</td>\n",
       "      <td>1.940954</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.733333</td>\n",
       "      <td>3.910373</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.533333</td>\n",
       "      <td>3.995188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.466667</td>\n",
       "      <td>3.960466</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.266667</td>\n",
       "      <td>-1.918701</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  predicted_sentiment  sentiment_ispositive  \\\n",
       "0   2.266667             2.511515                     1   \n",
       "1   3.533333             3.999904                     1   \n",
       "2  -0.600000            -3.655976                     0   \n",
       "3   1.466667             1.940954                     1   \n",
       "4   1.733333             3.910373                     1   \n",
       "5   2.533333             3.995188                     1   \n",
       "6   2.466667             3.960466                     1   \n",
       "7   1.266667            -1.918701                     1   \n",
       "\n",
       "   predicted_ispositive  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     0  \n",
       "3                     1  \n",
       "4                     1  \n",
       "5                     1  \n",
       "6                     1  \n",
       "7                     0  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[\"sentiment_ispositive\"] = (movies.sentiment > 0).astype(int)\n",
    "movies[\"predicted_ispositive\"] = (movies.predicted_sentiment > 0).astype(int)\n",
    "movies[\"sentiment predicted_sentiment sentiment_ispositive predicted_ispositive\".split()].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2fc370a1-fc7f-4352-9579-740a2ab9817e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344648750589345"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(movies.predicted_ispositive == movies.sentiment_ispositive).sum() / len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d494339-1694-47d8-b25b-4b347b946137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
